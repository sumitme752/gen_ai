{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Agenda\n",
    "1. installation\n",
    "2. how to load llm with langchain\n",
    "3. Promt template\n",
    "4. chains\n",
    "5. Agents and tools\n",
    "6. memory\n",
    "7. document loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup enviroment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumitkumar/Desktop/sumit_dir/data_science/Gen Ai/langchain/langc/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n",
      "/Users/sumitkumar/Desktop/sumit_dir/data_science/Gen Ai/langchain/langc/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "llm_model=HuggingFaceHub(huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN,repo_id=\"google/gemma-7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumitkumar/Desktop/sumit_dir/data_science/Gen Ai/langchain/langc/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want python code to add two numbers and then print the result.\n",
      "\n",
      "Answer:\n",
      "\n",
      "Step 1/2\n",
      "First, we need to import the math module to use the addition function. ```python import math ```\n",
      "\n",
      "Step 2/2\n",
      "Next, we can define a function called add that takes two arguments and returns the sum of those arguments. ```python def add(a, b): return a + b ``` Now, we can use the add function to add two numbers and print the result. ```python a = \n"
     ]
    }
   ],
   "source": [
    "print(llm_model(\"I want python code to add two numbers\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm=OpenAI(temperature= 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"What would be a company name for a company make colorful socks?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.predict(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_new=HuggingFaceHub(repo_id=\"Helsinki-NLP/opus-mt-en-hi\", model_kwargs={\"temperature\":0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "आप कैसे हैं?\n"
     ]
    }
   ],
   "source": [
    "print(llm_model_new(\"translate English to Hindi: How are you?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "pro = HuggingFaceHub(repo_id=\"google/gemma-7b\", model_kwargs={\"temperature\":0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the capital of jharkhand\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['input_name'],\n",
    "    template=\"what is the capital of {input_name}\"\n",
    ")\n",
    "p = prompt_template_name.format(input_name=\"jharkhand\")\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the capital of jharkhand\n",
      "\n",
      "Answer:\n",
      "\n",
      "Step 1/4\n",
      "1. The question is asking for the capital of Jharkhand.\n",
      "\n",
      "Step 2/4\n",
      "2. Jharkhand is a state in India.\n",
      "\n",
      "Step 3/4\n",
      "3. The capital of Jharkhand is Ranchi.\n",
      "\n",
      "Step 4/4\n",
      "4. Therefore, the answer is Ranchi.\n"
     ]
    }
   ],
   "source": [
    "print(pro(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "pro = HuggingFaceHub(repo_id=\"google/gemma-7b\", model_kwargs={\"temperature\":0.5})\n",
    "\n",
    "prompt_template_name = PromptTemplate.from_template(\"what is the capital of {product}\")\n",
    "# prompt_template_name.format(product=\"jharkhand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumitkumar/Desktop/sumit_dir/data_science/Gen Ai/langchain/langc/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "/Users/sumitkumar/Desktop/sumit_dir/data_science/Gen Ai/langchain/langc/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the capital of west bengal\n",
      "\n",
      "Answer:\n",
      "\n",
      "Step 1/5\n",
      "1. West Bengal is a state in India.\n",
      "\n",
      "Step 2/5\n",
      "2. The capital of a state is the city where the state government is headquartered.\n",
      "\n",
      "Step 3/5\n",
      "3. Therefore, we need to find out which city in West Bengal is the state capital.\n",
      "\n",
      "Step 4/5\n",
      "4. The capital of West Bengal is Kolkata.\n",
      "\n",
      "Step 5/5\n",
      "5. Therefore, the answer\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain=LLMChain(llm=pro, prompt=prompt_template_name)\n",
    "response= chain.run(\"west bengal\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mwhat is the capital of west bengal\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "what is the capital of west bengal\n",
      "\n",
      "Answer:\n",
      "\n",
      "Step 1/5\n",
      "1. West Bengal is a state in India.\n",
      "\n",
      "Step 2/5\n",
      "2. The capital of a state is the city where the state government is headquartered.\n",
      "\n",
      "Step 3/5\n",
      "3. Therefore, we need to find out which city in West Bengal is the state capital.\n",
      "\n",
      "Step 4/5\n",
      "4. The capital of West Bengal is Kolkata.\n",
      "\n",
      "Step 5/5\n",
      "5. Therefore, the answer\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain=LLMChain(llm=pro, prompt=prompt_template_name,verbose=True)\n",
    "response= chain.run(\"west bengal\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm = HuggingFaceHub(repo_id=\"google/gemma-7b\", model_kwargs={\"temperature\":0.6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['input_name'],\n",
    "    template=\"what is the capital of {input_name}?\"\n",
    ")\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['item_name'],\n",
    "    template=\"Best {item_name} street food?\"\n",
    ")\n",
    "food_item_chain = LLMChain(llm=llm, prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = SimpleSequentialChain(chains= [name_chain, food_item_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best what is the capital of indian?\n",
      "\n",
      "Answer:\n",
      "\n",
      "Step 1/2\n",
      "The capital of India is New Delhi.\n",
      "\n",
      "Step 2/2\n",
      "It is located in the northern part of the country and serves as the administrative and political center of the nation. New Delhi is a modern city with wide boulevards, beautiful gardens, and a rich cultural heritage. The city is home to many important landmarks, including the iconic India Gate, the majestic Rashtrapati Bhavan, and the historic Red Fort. New Delhi street food? The street food in New Delhi is a gastronomic delight for foodies. From the famous Chaat, Gol Gappas, and Pav Bhaji to the aromatic Biryani and Kebabs, the city offers a wide range of mouth-watering delicacies that are sure to tantalize your taste buds. The street food vendors in New Delhi are famous for their affordable and delicious cuisine, which is enjoyed by locals and tourists alike. Some of the best street food in New Delhi can be found at the\n"
     ]
    }
   ],
   "source": [
    "content=chain.run(\"indian\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in ./langc/lib/python3.9/site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in ./langc/lib/python3.9/site-packages (from google-search-results) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./langc/lib/python3.9/site-packages (from requests->google-search-results) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./langc/lib/python3.9/site-packages (from requests->google-search-results) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./langc/lib/python3.9/site-packages (from requests->google-search-results) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./langc/lib/python3.9/site-packages (from requests->google-search-results) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumitkumar/Desktop/sumit_dir/data_science/Gen Ai/langchain/langc/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [wikipedia, Calculator]\n",
      "Action Input: the input to the action\u001b[0m\n",
      "Observation: the action to take, should be one of [wikipedia, Calculator] is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [wikipedia, Calculator]\n",
      "Action Input: the input to the action\u001b[0m\n",
      "Observation: the action to take, should be one of [wikipedia, Calculator] is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [wikipedia, Calculator]\n",
      "Action Input: the input to the action\u001b[0m\n",
      "Observation: the action to take, should be one of [wikipedia, Calculator] is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [wikipedia, Calculator]\n",
      "Action Input: the input to the action\u001b[0m\n",
      "Observation: the action to take, should be one of [wikipedia, Calculator] is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [wikipedia, Calculator]\n",
      "Action Input: the input to the action\u001b[0m\n",
      "Observation: the action to take, should be one of [wikipedia, Calculator] is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [wikipedia, Calculator]\n",
      "Action Input: the input to the action\u001b[0m\n",
      "Observation: the action to take, should be one of [wikipedia, Calculator] is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [wikipedia, Calculator]\n",
      "Action Input: the input to the action\u001b[0m\n",
      "Observation: the action to take, should be one of [wikipedia, Calculator] is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [wikipedia, Calculator]\n",
      "Action Input: the input to the action\u001b[0m\n",
      "Observation: the action to take, should be one of [wikipedia, Calculator] is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [wikipedia, Calculator]\n",
      "Action Input: the input to the action\u001b[0m\n",
      "Observation: the action to take, should be one of [wikipedia, Calculator] is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [wikipedia, Calculator]\n",
      "Action Input: the input to the action\u001b[0m\n",
      "Observation: the action to take, should be one of [wikipedia, Calculator] is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [wikipedia, Calculator]\n",
      "Action Input: the input to the action\u001b[0m\n",
      "Observation: the action to take, should be one of [wikipedia, Calculator] is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [wikipedia, Calculator]\n",
      "Action Input: the input to the action\u001b[0m\n",
      "Observation: the action to take, should be one of [wikipedia, Calculator] is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [wikipedia, Calculator]\n",
      "Action Input: the input to the action\u001b[0m\n",
      "Observation: the action to take, should be one of [wikipedia, Calculator] is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [wikipedia, Calculator]\n",
      "Action Input: the input to the action\u001b[0m\n",
      "Observation: the action to take, should be one of [wikipedia, Calculator] is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [wikipedia, Calculator]\n",
      "Action Input: the input to the action\u001b[0m\n",
      "Observation: the action to take, should be one of [wikipedia, Calculator] is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Agent stopped due to iteration limit or time limit.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain import HuggingFaceHub\n",
    "\n",
    "llm = HuggingFaceHub(repo_id=\"google/gemma-7b\", model_kwargs={\"temperature\":0.6})\n",
    "\n",
    "tools=load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
    "\n",
    "agent=initialize_agent(tools,llm,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)\n",
    "\n",
    "agent.run(\"What is the capital of indai?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm = HuggingFaceHub(repo_id=\"google/gemma-7b\", model_kwargs={\"temperature\":0.6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['input_name'],\n",
    "    template=\"what is the capital of {input_name}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the capital of India?\n",
      "\n",
      "Answer:\n",
      "\n",
      "Step 1/2\n",
      "First, we need to know the country. India is a country in South Asia. Second, we need to know the capital of India. According to the Constitution of India, the capital of India is New Delhi.\n",
      "\n",
      "Step 2/2\n",
      "So, the answer to the question \"What is the capital of India?\" is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "name = name_chain.run(\"India\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the capital of Pakistan?\n",
      "\n",
      "Answer:\n",
      "\n",
      "The capital of\n",
      "Pakistan is Islamabad.\n"
     ]
    }
   ],
   "source": [
    "name = name_chain.run(\"Pakistan\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(name_chain.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational buffer memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the capital of India?\n",
      "\n",
      "Answer:\n",
      "\n",
      "Step 1/2\n",
      "First, we need to know the country. India is a country in South Asia. Second, we need to know the capital of India. According to the Constitution of India, the capital of India is New Delhi.\n",
      "\n",
      "Step 2/2\n",
      "So, the answer to the question \"What is the capital of India?\" is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
    "name = chain.run(\"India\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the capital of Pakistan?\n",
      "\n",
      "Answer:\n",
      "\n",
      "The capital of\n",
      "Pakistan is Islamabad.\n"
     ]
    }
   ],
   "source": [
    "name = chain.run(\"Pakistan\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: India\n",
      "AI: what is the capital of India?\n",
      "\n",
      "Answer:\n",
      "\n",
      "Step 1/2\n",
      "First, we need to know the country. India is a country in South Asia. Second, we need to know the capital of India. According to the Constitution of India, the capital of India is New Delhi.\n",
      "\n",
      "Step 2/2\n",
      "So, the answer to the question \"What is the capital of India?\" is New Delhi.\n",
      "Human: Pakistan\n",
      "AI: what is the capital of Pakistan?\n",
      "\n",
      "Answer:\n",
      "\n",
      "The capital of\n",
      "Pakistan is Islamabad.\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversatation window buffer memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the capital of India?\n",
      "\n",
      "Answer:\n",
      "\n",
      "Step 1/2\n",
      "First, we need to know the country. India is a country in South Asia. Second, we need to know the capital of India. According to the Constitution of India, the capital of India is New Delhi.\n",
      "\n",
      "Step 2/2\n",
      "So, the answer to the question \"What is the capital of India?\" is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
    "name = chain.run(\"India\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the capital of Pakistan?\n",
      "\n",
      "Answer:\n",
      "\n",
      "The capital of\n",
      "Pakistan is Islamabad.\n"
     ]
    }
   ],
   "source": [
    "name = chain.run(\"Pakistan\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Pakistan\n",
      "AI: what is the capital of Pakistan?\n",
      "\n",
      "Answer:\n",
      "\n",
      "The capital of\n",
      "Pakistan is Islamabad.\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"1-Simple Linear Regression.pdf\")\n",
    "pages= loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '1-Simple Linear Regression.pdf', 'page': 0}, page_content='Sumit Kumar\\nData Scientist\\n\\xa0\\xa0sumitme752@gmail.com \\xa0  (+91) 8553282301 \\xa0 \\xa0 \\xa0 \\xa0Bangalore, India\\n\\xa0 Career Summary\\nMotivated professional with 4 years of experience in Data Science and Analytics (total exp 6 years) . Experienced at interpreting and\\nanalyzing data to drive solutions, and furnish insights and business intelligence needed to guide decisions for a business problem.\\nPassionate about building models that \\x00x issues. Relevant skills include machine learning, problem-solving, programming and creative\\nthinking. Also, I have experience in training & guiding individuals on ML and related topics.\\n\\xa0 \\xa0 Skills\\nStatistical Analysis -\\xa0Exploratory Data Analysis, Inferential Statistics, Hypothesis Testing\\nMachine Learning & AI\\xa0- \\xa0\\nAlgorithms: Decision Tree, Random Forest, XG Boost, Linear Regression, Logistic Regression, SVM, KNN\\nNLP: Text preprocessing,\\xa0Deep Learning - ANN , RNN ,CNN\\nProgramming Languages & Databases - Python , SQL\\nFrameworks\\xa0\\xa0- NumPy, Pandas, Sci-kit learn, SciPy\\nTools/IDE\\xa0-\\xa0VS Code, Jupyter Notebook , Excel , Git\\nOperating Syste- Windows , Linux , MacOS\\nWeb Development - HTML, CSS, \\xa0ReactJs\\n \\n\\xa0 Work Experience\\n1. Pravartan Technologies - Data Scientist\\xa0( Mar 2023 - Present)\\nProjects\\n1. Data Quality Analysis and Dashboarding\\nGoal :\\xa0This project focuses on assessing and visualizing the completeness and accuracy of data using a combination of tools and\\ntechnologies, including Excel, Python, Power BI, and Snow\\x00ake. The primary goal is to ensure the integrity of data and provide\\nactionable insights through comprehensive dashboards.\\nRoles & Responsibilities\\nData Extraction: Connect to Snow\\x00ake and extract relevant datasets.\\nData Analysis: Using excel perform preliminary data checks, cleaning, and basic completeness analysis.\\xa0Conduct advanced data\\nanalysis to identify incorrect data and automate quality checks.\\nDashboard Development: Used Power BI to create dynamic dashboards that provide visual insights into data quality metrics.\\nReview and Reporting: Compile \\x00ndings into comprehensive reports and suggest actionable recommendations for data quality\\nimprovement.\\n2. \\xa0Automated Form Filling Using Data Preparation and Analysis\\nGoal : This project demonstrates a proof of concept (POC) for automating the process of \\x00lling blank forms with valid answers. Focuses\\non data preparation and analysis, leveraging Azure Computer Vision to convert PDF forms into JSON format for further processing. This\\nwill \\xa0signi\\x00cantly reduce manual effort and increase accuracy.\\xa0\\nRoles & Responsibilities\\nData Preparation: Collect and clean data required for \\x00lling forms, ensuring it is structured and ready for analysis.'),\n",
       " Document(metadata={'source': '1-Simple Linear Regression.pdf', 'page': 1}, page_content='Data Analysis: Conducting thorough analysis to validate the data, ensuring accuracy and completeness for form entries and\\ndocumenting\\xa0the data analysis process and validation results.\\nPDF to JSON Conversion: Used Azure Computer Vision to convert PDF forms into JSON format, enabling structured data extraction.\\nAutomated Form Filling: Develop scripts to automate the process of populating blank forms with valid answers based on the\\nprepared and analyzed data.\\n2. Skoruz Technologies - Data Scientist ( Jan 2022 - Sept 2022)\\nProjects\\n1. Goal -\\xa0To help J&J with \"Prediction of Leadtime\" and \"Choosing the best lead time prediction value\" among the different lead time\\npredictions available.\\nDescription -\\xa0Leadtime\\xa0is no. of delivery days required to deliver an incoming order. The prediction we provided is called \"d2\" prediction;\\nsimilarly, J&J has other mechanisms to make the predictions. So providing them with solutions and helping them with choosing the best\\namong the available prediction values. The project has four components - data extraction & pre-processing, D2 training, method\\nselection training, and live prediction.\\nRoles & Responsibilities\\nEDA - Treatment of missing values, Encoding of categorical features, Capping & \\x00ooring for outliers\\xa0\\nDecision trees, Random forest, Logistic regression, and XGB are used for model building.\\nThe model with the best performance metrics is XGB with an accuracy of 89% and precision of 72%.\\n3. Flatworld Solutions - ML Engineer (May 2019 - July 2021)\\nProjects\\n1. Goal -\\xa0Create a proactive customer retention strategy for a telecom company. To identify which customers would churn for a\\ntelecom company based on their usage behavior. This is a Customer Retention Strategy. A predictive model is created using\\nclassi\\x00cation algorithms and based on the prediction, a strategy can be made to target the pro\\x00table customers and retain them.\\nRoles & Responsibilities\\nExploratory data analysis to get better insights by treating missing values, outliers, and null values.\\nEncoding of categorical features and\\xa0analysis of correlations between numeric variables.\\nDecision trees, Random forest, and Logistic regression are used for model building.\\nTo improve model performance, hyperparameter tuning using grid-search cv for Decision Tree and Random Forest.\\nThe model with the best performance metrics is Random Forest, and was chosen to create the strategy.\\n4. Rama Engicons (India) Pvt. Ltd -\\xa0Design engineer (October 2016 - April 2019)\\nModelling and Detailing of Sheet Metal Components-The objective of the project was to convert the 2D drawings to 3D sheet metal\\nmodels that could be directly fed for manufacturing.\\nSoundproof Enclosure-\\xa0This project was about sound and leak-proof enclosures.\\n\\xa0Education\\n2012-2016 2021\\nNew Horizon College of Engineering ( VTU University) \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0Data Science and AI Certi\\x00cate by IBM (Learnbay)\\nB.tech\\n\\xa0Language\\nEnglish , Hindi , Kanada\\xa0Interest\\nMixed Martial\\xa0Arts ,\\xa0Trekking , Cricket')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
